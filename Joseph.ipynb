{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stock_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 73\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstats\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m spearmanr\n\u001b[1;32m---> 73\u001b[0m stock_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(stock_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mdate\n\u001b[0;32m     74\u001b[0m daily_sentiment[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(daily_sentiment[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mdate\n\u001b[0;32m     76\u001b[0m combined_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mmerge(stock_data, daily_sentiment, left_on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m, right_on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m, how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minner\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'stock_data' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import nltk\n",
    "import re\n",
    "data = pd.read_csv('Tesla.csv')\n",
    "cleaned_data = pd.DataFrame()\n",
    "cleaned_data['original_tweet'] = data['tweet']\n",
    "cleaned_data['cleaned_tweet'] = \"\"\n",
    "cleaned_data['sentiment'] = \"\"\n",
    "cleaned_data['compound_score'] = 0.0\n",
    "cleaned_data['positive_score'] = 0.0\n",
    "cleaned_data['negative_score'] = 0.0\n",
    "cleaned_data['neutral_score'] = 0.0\n",
    "#Preprocess our data to be a valid input for VADER\n",
    "# --> VADER can handle emojis, punctuation, capitalization, slang, and negations ... so don't need to remove these items\n",
    "\n",
    "cleaned_tweets = []\n",
    "for tweet in data[\"tweet\"]:\n",
    "    tweet = str(tweet)\n",
    "\n",
    "    #remove urls\n",
    "    tweet = re.sub(r'http\\S+|www\\S+|https\\S+', '', tweet)\n",
    "\n",
    "    #remove @'s\n",
    "    tweet = re.sub(r'@\\w+', '', tweet)\n",
    "\n",
    "    #remove #'s\n",
    "    tweet = re.sub(r'#', '', tweet)\n",
    "\n",
    "    #remove special chars\n",
    "    tweet = re.sub(r'[^\\w\\s]', '', tweet)\n",
    "\n",
    "    #remove nums\n",
    "    tweet = re.sub(r'\\d+', '', tweet)\n",
    "\n",
    "    #remove extra spaces\n",
    "    tweet = tweet.strip()\n",
    "\n",
    "    #add cleaned tweet to the arr\n",
    "    cleaned_tweets.append(tweet)\n",
    "\n",
    "cleaned_data[\"cleaned_tweet\"] = cleaned_tweets\n",
    "#create a VADER setniment analyzer:\n",
    "sentiment_analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Get the sentiment/polarity score of each tweet:\n",
    "for i in range(len(cleaned_data)):\n",
    "\n",
    "    curr_tweet = cleaned_data[\"cleaned_tweet\"][i]\n",
    "    \n",
    "    # curr_score is a dictionary that stores a positive, negative, neutral, and compound score for an individual tweet\n",
    "    curr_score = sentiment_analyzer.polarity_scores(curr_tweet)\n",
    "\n",
    "    cleaned_data.loc[i, \"compound_score\"] = curr_score[\"compound\"]\n",
    "    cleaned_data.loc[i, \"positive_score\"] = curr_score[\"pos\"]\n",
    "    cleaned_data.loc[i, \"negative_score\"] = curr_score[\"neg\"]\n",
    "    cleaned_data.loc[i, \"neutral_score\"] = curr_score[\"neu\"]\n",
    "\n",
    "    # Determine sentiment category\n",
    "    if curr_score['compound'] >= 0.05:\n",
    "        cleaned_data.loc[i, 'sentiment'] = 'Positive'\n",
    "    elif curr_score['compound'] <= -0.05:\n",
    "        cleaned_data.loc[i, 'sentiment'] = 'Negative'\n",
    "    else:\n",
    "        cleaned_data.loc[i, 'sentiment'] = 'Neutral'\n",
    "\n",
    "# ////////////////////////////\n",
    "\n",
    "import pandas as pd\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "stock_data['Date'] = pd.to_datetime(stock_data['Date']).dt.date\n",
    "daily_sentiment['date'] = pd.to_datetime(daily_sentiment['date']).dt.date\n",
    "\n",
    "combined_data = pd.merge(stock_data, daily_sentiment, left_on='Date', right_on='date', how='inner')\n",
    "\n",
    "combined_data.drop(columns='date', inplace=True)\n",
    "\n",
    "stock_prices = combined_data['Close']\n",
    "compound_scores = combined_data['compound_score']\n",
    "\n",
    "rho, p_value = spearmanr(stock_prices, compound_scores)\n",
    "print(\"Spearman's correlation (rho) between Close price and compound_score:\", rho)\n",
    "print(\"p-value:\", p_value)\n",
    "\n",
    "sentiment_columns = ['compound_score', 'positive_score', 'negative_score', 'neutral_score']\n",
    "\n",
    "for sentiment_col in sentiment_columns:\n",
    "    rho, p_value = spearmanr(combined_data['Close'], combined_data[sentiment_col])\n",
    "    print(f\"Spearman's correlation between Close and {sentiment_col}: rho={rho:.4f}, p={p_value:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
